#!/usr/bin/env python3
"""
Offline Model Setup Guide
Helps set up Hugging Face models for offline use
"""

import sys
import os
from datetime import datetime

# Add the parent directory to the path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def check_installation():
    """Check what's already installed"""
    print("ğŸ” Checking Current Installation")
    print("=" * 50)
    
    packages = {
        "transformers": "Hugging Face Transformers library",
        "torch": "PyTorch for model inference",
        "sentence-transformers": "Sentence embeddings",
        "langchain": "LangChain framework",
        "accelerate": "Model acceleration utilities"
    }
    
    installed = {}
    
    for package, description in packages.items():
        try:
            # Use a more robust import method
            if package == "torch":
                import torch
                version = torch.__version__
            elif package == "sentence-transformers":
                # Handle hyphenated package name correctly
                import sentence_transformers
                version = sentence_transformers.__version__
            elif package == "transformers":
                import transformers
                version = transformers.__version__
            elif package == "langchain":
                import langchain
                version = langchain.__version__
            elif package == "accelerate":
                import accelerate
                version = accelerate.__version__
            else:
                module = __import__(package)
                version = getattr(module, '__version__', 'Unknown')
            
            installed[package] = version
            print(f"âœ… {package}: {version} - {description}")
        except ImportError as e:
            installed[package] = None
            print(f"âŒ {package}: Not installed - {description}")
            print(f"   Error: {e}")
        except Exception as e:
            installed[package] = None
            print(f"âŒ {package}: Error checking - {description}")
            print(f"   Error: {e}")
    
    return installed

def install_packages():
    """Guide through package installation"""
    print("\nğŸ“¦ Package Installation Guide")
    print("=" * 50)
    
    print("ğŸš€ **Step 1: Install Core Libraries**")
    print("Run these commands in your terminal:")
    print()
    
    commands = [
        "pip install transformers",
        "pip install torch",
        "pip install sentence-transformers",
        "pip install langchain langchain-community",
        "pip install accelerate safetensors"
    ]
    
    for cmd in commands:
        print(f"   {cmd}")
    
    print()
    print("ğŸ’¡ **Note**: This step requires internet connection")
    print("ğŸ’¡ **After installation**: Models will work offline")
    
    return commands

def download_models():
    """Guide through model downloading"""
    print("\nğŸ“¥ Model Download Guide")
    print("=" * 50)
    
    print("ğŸš€ **Step 2: Download Models (One-time setup)**")
    print("Run this script to download models:")
    print()
    
    script_content = '''#!/usr/bin/env python3
"""
Model Downloader Script
Downloads models for offline use
"""

def download_models():
    print("ğŸ“¥ Downloading models for offline use...")
    
    models = [
        "microsoft/DialoGPT-small",      # Small chat model
        "sentence-transformers/all-MiniLM-L6-v2",  # Embeddings
        "gpt2"                           # Text generation
    ]
    
    for model_name in models:
        try:
            print(f"\\nğŸ“¥ Downloading: {model_name}")
            
            if "sentence-transformers" in model_name:
                from sentence_transformers import SentenceTransformer
                model = SentenceTransformer(model_name)
                print(f"âœ… {model_name} downloaded successfully")
            else:
                from transformers import AutoTokenizer, AutoModelForCausalLM
                tokenizer = AutoTokenizer.from_pretrained(model_name)
                model = AutoModelForCausalLM.from_pretrained(model_name)
                print(f"âœ… {model_name} downloaded successfully")
                
        except Exception as e:
            print(f"âŒ Failed to download {model_name}: {e}")
    
    print("\\nğŸ‰ Model download complete!")
    print("ğŸ’¡ These models will now work offline")

if __name__ == "__main__":
    download_models()
'''
    
    # Save the script
    script_path = os.path.join(os.path.dirname(__file__), "download_models.py")
    with open(script_path, 'w') as f:
        f.write(script_content)
    
    print(f"ğŸ“ Script saved to: {script_path}")
    print("ğŸ’» Run it with: python download_models.py")
    print()
    print("ğŸ’¡ **Note**: This step requires internet connection")
    print("ğŸ’¡ **After download**: Models cached locally")

def test_offline_mode():
    """Test if models can work offline"""
    print("\nğŸ§ª Testing Offline Mode")
    print("=" * 50)
    
    try:
        # Try to import transformers
        import transformers
        print("âœ… Transformers library available")
        
        # Check cache directory
        cache_dir = transformers.file_utils.default_cache_path
        print(f"ğŸ“ Cache directory: {cache_dir}")
        
        if os.path.exists(cache_dir):
            print("âœ… Cache directory exists")
            
            # Look for downloaded models
            cache_contents = os.listdir(cache_dir)
            model_dirs = [d for d in cache_contents if os.path.isdir(os.path.join(cache_dir, d))]
            
            if model_dirs:
                print(f"âœ… Found {len(model_dirs)} cached models:")
                for model_dir in model_dirs[:5]:  # Show first 5
                    print(f"   ğŸ“¦ {model_dir}")
                if len(model_dirs) > 5:
                    print(f"   ... and {len(model_dirs) - 5} more")
            else:
                print("âš ï¸ No cached models found")
        else:
            print("âŒ Cache directory not found")
        
        return True
        
    except ImportError:
        print("âŒ Transformers not installed")
        return False
    except Exception as e:
        print(f"âŒ Error checking offline mode: {e}")
        return False

def create_offline_test():
    """Create a test script for offline model usage"""
    print("\nğŸ”§ Creating Offline Test Script")
    print("=" * 50)
    
    test_script = '''#!/usr/bin/env python3
"""
Offline Model Test
Tests if models work without internet
"""

def test_offline_models():
    print("ğŸ§ª Testing Offline Model Usage")
    print("=" * 40)
    
    try:
        # Test 1: Load model from cache
        print("ğŸ“¥ Loading model from local cache...")
        from transformers import AutoTokenizer, AutoModelForCausalLM
        import torch
        
        # Use local_files_only=True to prevent internet connection
        tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-small', local_files_only=True)
        model = AutoModelForCausalLM.from_pretrained('microsoft/DialoGPT-small', local_files_only=True)
        print("âœ… Model loaded from cache - no internet needed!")
        
        # Test 2: Generate text
        print("\\nğŸ’¬ Testing text generation...")
        input_text = "Hello, how are you?"
        inputs = tokenizer.encode(input_text, return_tensors="pt")
        
        with torch.no_grad():
            outputs = model.generate(inputs, max_length=50, num_return_sequences=1)
        
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        print(f"âœ… Generated response: {response}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Offline test failed: {e}")
        print("ğŸ’¡ Make sure models are downloaded first")
        return False

if __name__ == "__main__":
    test_offline_models()
'''
    
    # Save the test script
    test_path = os.path.join(os.path.dirname(__file__), "test_offline_models.py")
    with open(test_path, 'w') as f:
        f.write(test_script)
    
    print(f"ğŸ“ Offline test script saved to: {test_path}")
    print("ğŸ’» Run it with: python test_offline_models.py")

def provide_offline_workflow():
    """Provide complete offline workflow"""
    print("\nğŸ”„ Complete Offline Workflow")
    print("=" * 50)
    
    print("ğŸš€ **Step-by-Step Process:**")
    print()
    print("1ï¸âƒ£ **Install Libraries** (needs internet ONCE)")
    print("   pip install transformers torch sentence-transformers")
    print()
    print("2ï¸âƒ£ **Download Models** (needs internet ONCE)")
    print("   python download_models.py")
    print()
    print("3ï¸âƒ£ **Test Offline Mode** (no internet needed)")
    print("   python test_offline_models.py")
    print()
    print("4ï¸âƒ£ **Use in Your Application** (no internet needed)")
    print("   Models work from local cache")
    print()
    print("ğŸ’¡ **Key Points:**")
    print("   â€¢ Installation: One-time internet needed")
    print("   â€¢ Model download: One-time internet needed")
    print("   â€¢ Usage: Completely offline")
    print("   â€¢ Cache: Models stored locally")
    print("   â€¢ Updates: Manual when needed")

def main():
    """Main function"""
    print("ğŸš€ Hugging Face Offline Setup Guide")
    print("=" * 60)
    print(f"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # Check current installation
    installed = check_installation()
    
    # Provide installation guide
    install_packages()
    
    # Guide through model downloading
    download_models()
    
    # Test offline capabilities
    test_offline_mode()
    
    # Create offline test script
    create_offline_test()
    
    # Provide complete workflow
    provide_offline_workflow()
    
    print("\n" + "=" * 60)
    print("ğŸ¯ SUMMARY")
    print("=" * 60)
    
    if any(installed.values()):
        print("âœ… Some packages already installed")
    else:
        print("âŒ No packages installed yet")
    
    print("\nğŸ’¡ **Next Steps:**")
    print("1. Install packages (if not done)")
    print("2. Download models (if not done)")
    print("3. Test offline functionality")
    print("4. Use models in your application")
    
    print("\nğŸš€ Setup guide complete!")

if __name__ == "__main__":
    main()
