# ğŸš€ LLM Models Configuration

## ğŸ“‹ **Default LLM Service Models**

The Agentic Mapping AI platform uses the following default models from your LLM service:

### ğŸ¤– **Primary Default Models**

| Provider | Model | Description |
|----------|-------|-------------|
| **Claude** | `claude-3-7-sonnet@20250219` | **Default Model** - Claude 3.7 Sonnet |
| **Gemini** | `gemini-2.5-pro` | Google Gemini 2.5 Pro |
| **Stellar** | `Meta-Llama-3.2-90B-Vision-Instruct` | Meta Llama 3.2 90B Vision |

### âš™ï¸ **Configuration**

The default model is configured in:
- **File**: `config/settings.py`
- **Setting**: `LLMSettings.default_model`
- **Current Value**: `claude-3-7-sonnet@20250219`

### ğŸ”§ **How to Change Default Model**

#### **Option 1: Environment Variable**
```bash
export LLM_DEFAULT_MODEL="gemini-2.5-pro"
```

#### **Option 2: Update Settings File**
```python
# In config/settings.py
class LLMSettings(BaseSettings):
    default_model: str = Field(default="gemini-2.5-pro")
    default_provider: str = Field(default="gemini")
```

#### **Option 3: Runtime Configuration**
```python
from config.settings import LLMSettings

llm_settings = LLMSettings()
llm_settings.default_model = "Meta-Llama-3.2-90B-Vision-Instruct"
```

### ğŸ¯ **Model Selection by Use Case**

| Use Case | Recommended Model | Reason |
|----------|-------------------|---------|
| **General AI Tasks** | `claude-3-7-sonnet@20250219` | Balanced performance and cost |
| **Code Generation** | `gemini-2.5-pro` | Excellent code understanding |
| **Vision Tasks** | `Meta-Llama-3.2-90B-Vision-Instruct` | Advanced vision capabilities |
| **High Performance** | `claude-3-7-sonnet@20250219` | Claude's reasoning capabilities |

### ğŸ“Š **Model Capabilities**

#### **Claude 3.7 Sonnet**
- âœ… **Reasoning**: Excellent for complex logic
- âœ… **Code**: Strong programming capabilities
- âœ… **Safety**: Built-in safety measures
- âœ… **Cost**: Balanced pricing

#### **Gemini 2.5 Pro**
- âœ… **Code**: Superior code generation
- âœ… **Multimodal**: Text, code, images
- âœ… **Performance**: High-speed processing
- âœ… **Integration**: Google ecosystem

#### **Meta Llama 3.2 90B Vision**
- âœ… **Vision**: Advanced image understanding
- âœ… **Open Source**: Community-driven
- âœ… **Customization**: Highly configurable
- âœ… **Multilingual**: Multiple languages

### ğŸš€ **Quick Start**

The demo automatically uses the default model from your LLM service. No additional configuration needed!

**Current Default**: `claude-3-7-sonnet@20250219`

### ğŸ“ **Notes**

- All models are accessed through your centralized LLM service
- Token-based authentication is used (no API keys needed)
- Models can be switched dynamically during runtime
- Fallback mechanisms ensure service availability
